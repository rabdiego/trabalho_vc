{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517a53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a0f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96848a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreloadedImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        transform = transform or transforms.ToTensor()\n",
    "\n",
    "        for label_dir in os.listdir(root_dir):\n",
    "            label_path = os.path.join(root_dir, label_dir)\n",
    "            if not os.path.isdir(label_path):\n",
    "                continue\n",
    "            label = 1 if label_dir == \"good\" else 0\n",
    "            for fname in tqdm(os.listdir(label_path)):\n",
    "                if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    path = os.path.join(label_path, fname)\n",
    "                    img = Image.open(path).convert(\"L\")\n",
    "                    img_tensor = transform(img).to(device)\n",
    "                    self.data.append(img_tensor)\n",
    "                    self.labels.append(torch.tensor(label, dtype=torch.float32, device=device))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ed373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008f213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleCNN(nn.Module):\n",
    "    def __init__(self, conv_layers=2, dense_layers=1, n_filters=16, hidden_dim=128, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels = 1\n",
    "        for _ in range(conv_layers):\n",
    "            layers += [\n",
    "                nn.Conv2d(in_channels, n_filters, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2)\n",
    "            ]\n",
    "            in_channels = n_filters\n",
    "            n_filters *= 2 \n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        reduced_size = 512 // (2 ** conv_layers)\n",
    "        flatten_size = in_channels * reduced_size * reduced_size\n",
    "\n",
    "        dense = [nn.Flatten()]\n",
    "        for _ in range(dense_layers):\n",
    "            dense.append(nn.Linear(flatten_size, hidden_dim))\n",
    "            dense.append(nn.ReLU())\n",
    "            dense.append(nn.Dropout(dropout_rate))\n",
    "            flatten_size = hidden_dim\n",
    "\n",
    "        dense.append(nn.Linear(flatten_size, 1))\n",
    "        dense.append(nn.Sigmoid())\n",
    "        self.classifier = nn.Sequential(*dense)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a199f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:12<00:00, 62.35it/s] \n",
      "100%|██████████| 260/260 [00:14<00:00, 18.41it/s]\n",
      "100%|██████████| 260/260 [00:01<00:00, 221.00it/s]\n",
      "100%|██████████| 280/280 [00:03<00:00, 73.41it/s]\n"
     ]
    }
   ],
   "source": [
    "full_dataset = PreloadedImageDataset('../data/', transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c394f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for images, labels in loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fdf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            outputs = model(images)\n",
    "            preds = (outputs > 0.5).int().cpu()\n",
    "            all_labels.extend(labels.cpu())\n",
    "            all_preds.extend(preds)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    prec = precision_score(all_labels, all_preds)\n",
    "    rec = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7ad50",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Hiperparâmetros a serem otimizados\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    n_filters = trial.suggest_categorical(\"n_filters\", [8, 16, 32])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.7)\n",
    "    conv_layers = trial.suggest_int(\"conv_layers\", 1, 4)\n",
    "    dense_layers = trial.suggest_int(\"dense_layers\", 1, 3)\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "\n",
    "    model = FlexibleCNN(conv_layers=conv_layers, dense_layers=dense_layers,\n",
    "                        n_filters=n_filters, hidden_dim=hidden_dim, dropout_rate=dropout).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    for epoch in range(3):  # curtos para otimização\n",
    "        train_model(model, train_loader, optimizer, criterion)\n",
    "\n",
    "    acc, _, _, _ = evaluate_model(model, test_loader)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edc56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-27 19:59:18,233] A new study created in memory with name: no-name-1e1435f1-d6fd-4c5f-823a-6cdc0be7940e\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_params\n",
    "model = FlexibleCNN(conv_layers=best[\"conv_layers\"], dense_layers=best[\"dense_layers\"],\n",
    "                    n_filters=best[\"n_filters\"], hidden_dim=best[\"hidden_dim\"],\n",
    "                    dropout_rate=best[\"dropout\"]).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=best[\"lr\"])\n",
    "criterion = nn.BCELoss()\n",
    "train_loader = DataLoader(train_dataset, batch_size=best[\"batch_size\"], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=best[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cdac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    train_model(model, train_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff33c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, prec, rec, f1 = evaluate_model(model, test_loader)\n",
    "print(f\"Acurácia: {acc:.4f} | Precisão: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Acurácia', 'Precisão', 'Recall', 'F1']\n",
    "values = [acc, prec, rec, f1]\n",
    "plt.bar(metrics, values)\n",
    "plt.title(\"Desempenho Final\")\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(\"metricas_final.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9775cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
